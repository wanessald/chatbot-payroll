# Chatbot Payroll

Este projeto Ã© um chatbot inteligente para responder dÃºvidas sobre folha de pagamento, utilizando LLM local e RAG para consultas precisas em dados reais.

---

## ğŸ›  Tecnologias usadas

- Python 3.13
- Streamlit
- Ollama (LLM local)
- Pandas (manipulaÃ§Ã£o de dados)
- python-dotenv (variÃ¡veis de ambiente)
- Pytest (testes)

---

## ğŸ“‚ Estrutura do projeto

chatbot-payroll/
â”œâ”€â”€ data/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py
â”‚ â”œâ”€â”€ llm.py
â”‚ â”œâ”€â”€ rag.py
â”‚ â”œâ”€â”€ utils.py
â”‚ â””â”€â”€ config.py
â”œâ”€â”€ tests/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

---

## âš¡ Setup inicial

1. **Instalar Poetry** (se ainda nÃ£o tiver):

```
pip install poetry
```

2. **Clonar repositÃ³rio e entrar na pasta:**

```
git clone https://github.com/seuuser/chatbot-payroll.git
cd chatbot-payroll
```

3. **Instalar dependÃªncias e criar virtualenv:**

```
poetry install
```

4. **Configurar variÃ¡veis de ambiente:**

Crie um arquivo `.env` na raiz do projeto baseado no `.env.example`. Nele, vocÃª pode definir variÃ¡veis como o modelo do Ollama, chaves de API e URLs de serviÃ§os externos, por exemplo:

```
OLLAMA_MODEL=llama3
API_KEY=sua-chave-aqui
SERVICE_URL=https://api.exemplo.com
```

---

## ğŸš€ Como rodar

```
poetry run streamlit run src/main.py
```

- Digite sua pergunta na interface e o chatbot irÃ¡ responder.
- Para consultas sobre folha de pagamento, ele tambÃ©m retorna evidÃªncia em JSON.

---

## ğŸ§ª Rodar testes

```
poetry run pytest -v
```

---

## ğŸ“ DecisÃµes tÃ©cnicas

- src/: separaÃ§Ã£o do cÃ³digo fonte do projeto, evitando problemas de importaÃ§Ã£o e melhor organizaÃ§Ã£o.
- RAG simples com Pandas: consulta direta no CSV com filtros e retorna evidÃªncias.
- LLM Ollama local: permite respostas gerais e contexto da folha.
- Poetry: gerenciamento moderno de dependÃªncias, ambiente virtual isolado e lockfile para reprodutibilidade.
